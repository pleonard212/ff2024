{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "608e5087",
   "metadata": {},
   "source": [
    "# Build a list of images to analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43bdb3be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Photos found: 32765\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "photos_path = Path(\"images/\")\n",
    "photos_files = list(photos_path.glob(\"*.jpg\"))\n",
    "print(f\"Photos found: {len(photos_files)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd70b6a",
   "metadata": {},
   "source": [
    "# Define function to compute embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "832db2ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cuda\n"
     ]
    }
   ],
   "source": [
    "import clip\n",
    "import torch\n",
    "from PIL import Image\n",
    "#device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using device \" + device)\n",
    "model, preprocess = clip.load(\"ViT-B/32\", device=device)\n",
    "\n",
    "def compute_embedding(photos_batch):\n",
    "    # Load all the photos from the files\n",
    "    photos = [Image.open(photo_file) for photo_file in photos_batch]\n",
    "    \n",
    "    # Preprocess all photos\n",
    "    photos_preprocessed = torch.stack([preprocess(photo) for photo in photos]).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Encode the photos batch to compute the feature vectors and normalize them\n",
    "        photos_features = model.encode_image(photos_preprocessed)\n",
    "        photos_features /= photos_features.norm(dim=-1, keepdim=True)\n",
    "\n",
    "    # Transfer the feature vectors back to the CPU and convert to numpy\n",
    "    return photos_features.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb68ec29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 1 of 16\n",
      "Processing batch 2 of 16\n",
      "Processing batch 3 of 16\n",
      "Processing batch 4 of 16\n",
      "Processing batch 5 of 16\n",
      "Processing batch 6 of 16\n",
      "Processing batch 7 of 16\n",
      "Processing batch 8 of 16\n",
      "Processing batch 9 of 16\n",
      "Processing batch 10 of 16\n",
      "Processing batch 11 of 16\n",
      "Problem with batch 10\n",
      "Processing batch 12 of 16\n",
      "Processing batch 13 of 16\n",
      "Processing batch 14 of 16\n",
      "Processing batch 15 of 16\n",
      "Processing batch 16 of 16\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "#batch_size = 256\n",
    "batch_size=8192\n",
    "\n",
    "# Save the resulting embeddings here:\n",
    "features_path = Path(\"features/\")\n",
    "\n",
    "# Compute the rigt number of batches:\n",
    "batches = math.ceil(len(photos_files) / batch_size)\n",
    "\n",
    "# Process each batch\n",
    "for i in range(batches):\n",
    "    print(f\"Processing batch {i+1} of {batches}\")\n",
    "\n",
    "    batch_ids_path = features_path / f\"{i:010d}.csv\"\n",
    "    batch_features_path = features_path / f\"{i:010d}.npy\"\n",
    "    \n",
    "    # Only do the processing if the batch wasn't processed yet\n",
    "    if not batch_features_path.exists():\n",
    "        try:\n",
    "            # Select the photos for the current batch\n",
    "            batch_files = photos_files[i*batch_size : (i+1)*batch_size]\n",
    "\n",
    "            # Compute the features and save to a numpy file\n",
    "            batch_features = compute_embedding(batch_files)\n",
    "            np.save(batch_features_path, batch_features)\n",
    "\n",
    "            # Save the photo IDs to a CSV file\n",
    "            photo_ids = [photo_file.name.replace(\".jpg\",\"\") for photo_file in batch_files]\n",
    "            photo_ids_data = pd.DataFrame(photo_ids, columns=['photo_id'])\n",
    "            photo_ids_data.to_csv(batch_ids_path, index=False)\n",
    "        except:\n",
    "            # Error logging - possibilities include corrupt jpg, wrong format file, etc\n",
    "            print(f'Problem with batch {i}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c2a066",
   "metadata": {},
   "source": [
    "# Produce numpy and csv results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0473a526",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Load all of the embeddings we saved to disk\n",
    "features_list = [np.load(features_file) for features_file in sorted(features_path.glob(\"*.npy\"))]\n",
    "\n",
    "# Store all of the embeddings in one big file\n",
    "features = np.concatenate(features_list)\n",
    "np.save(features_path / \"features.npy\", features)\n",
    "\n",
    "# Write the metadata file\n",
    "photo_ids = pd.concat([pd.read_csv(ids_file) for ids_file in sorted(features_path.glob(\"*.csv\"))])\n",
    "photo_ids.to_csv(features_path / \"photo_ids.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a617996f-57f8-4079-8855-5526d2210b44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clipsearch",
   "language": "python",
   "name": "clipsearch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
