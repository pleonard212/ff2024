{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "608e5087",
   "metadata": {},
   "source": [
    "# Build a list of images to analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43bdb3be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Photos found: 19994\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "photos_path = Path(\"plimages/vrcstanford/\")\n",
    "photos_files = list(photos_path.glob(\"*.jpg\"))\n",
    "print(f\"Photos found: {len(photos_files)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72abda3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.9.13\r\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd70b6a",
   "metadata": {},
   "source": [
    "# Define function to compute embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "832db2ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device mps\n"
     ]
    }
   ],
   "source": [
    "import clip\n",
    "import torch\n",
    "from PIL import Image\n",
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "print(\"Using device \" + device)\n",
    "model, preprocess = clip.load(\"ViT-B/32\", device=device)\n",
    "\n",
    "def compute_embedding(photos_batch):\n",
    "    # Load all the photos from the files\n",
    "    photos = [Image.open(photo_file) for photo_file in photos_batch]\n",
    "    \n",
    "    # Preprocess all photos\n",
    "    photos_preprocessed = torch.stack([preprocess(photo) for photo in photos]).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Encode the photos batch to compute the feature vectors and normalize them\n",
    "        photos_features = model.encode_image(photos_preprocessed)\n",
    "        photos_features /= photos_features.norm(dim=-1, keepdim=True)\n",
    "\n",
    "    # Transfer the feature vectors back to the CPU and convert to numpy\n",
    "    return photos_features.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb68ec29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "batch_size = 256\n",
    "\n",
    "# Save the resulting embeddings here:\n",
    "features_path = Path(\"plfeatures/vrcstanford2/\")\n",
    "\n",
    "# Compute the rigt number of batches:\n",
    "batches = math.ceil(len(photos_files) / batch_size)\n",
    "\n",
    "# Process each batch\n",
    "for i in range(batches):\n",
    "    print(f\"Processing batch {i+1} of {batches}\")\n",
    "\n",
    "    batch_ids_path = features_path / f\"{i:010d}.csv\"\n",
    "    batch_features_path = features_path / f\"{i:010d}.npy\"\n",
    "    \n",
    "    # Only do the processing if the batch wasn't processed yet\n",
    "    if not batch_features_path.exists():\n",
    "        try:\n",
    "            # Select the photos for the current batch\n",
    "            batch_files = photos_files[i*batch_size : (i+1)*batch_size]\n",
    "\n",
    "            # Compute the features and save to a numpy file\n",
    "            batch_features = compute_embedding(batch_files)\n",
    "            np.save(batch_features_path, batch_features)\n",
    "\n",
    "            # Save the photo IDs to a CSV file\n",
    "            photo_ids = [photo_file.name.replace(\".jpg\",\"\") for photo_file in batch_files]\n",
    "            photo_ids_data = pd.DataFrame(photo_ids, columns=['photo_id'])\n",
    "            photo_ids_data.merge(df, how='left', on='photo_id')\n",
    "            photo_ids_data.to_csv(batch_ids_path, index=False)\n",
    "        except:\n",
    "            # Error logging - possibilities include corrupt jpg, wrong format file, etc\n",
    "            print(f'Problem with batch {i}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c2a066",
   "metadata": {},
   "source": [
    "# Produce numpy and csv results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0473a526",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Load all of the embeddings we saved to disk\n",
    "features_list = [np.load(features_file) for features_file in sorted(features_path.glob(\"*.npy\"))]\n",
    "\n",
    "# Store all of the embeddings in one big file\n",
    "features = np.concatenate(features_list)\n",
    "np.save(features_path / \"features.npy\", features)\n",
    "\n",
    "# Write the metadata file\n",
    "photo_ids = pd.concat([pd.read_csv(ids_file) for ids_file in sorted(features_path.glob(\"*.csv\"))])\n",
    "photo_ids.to_csv(features_path / \"photo_ids.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clipsearch",
   "language": "python",
   "name": "clipsearch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
